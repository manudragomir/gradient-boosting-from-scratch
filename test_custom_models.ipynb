{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import numpy as np\n",
    "from MyDecisionTree import MyDecisionTree\n",
    "from MyGradientBoostingRegressor import MyGradientBoostingRegressor\n",
    "from MyGradientBoostingMultiClassClassifier import MyGradientBoostingMultiClassClassifier\n",
    "from utils import REGRESSION, CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>8.7</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>23.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.00020</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.74</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.066</td>\n",
       "      <td>40.5</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.99120</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>10.9</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.118</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.088</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.99694</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>8.4</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.073</td>\n",
       "      <td>11.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.058</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.99770</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.073</td>\n",
       "      <td>25.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99638</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.077</td>\n",
       "      <td>15.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.99746</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.054</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.99458</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>5.8</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.063</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.99150</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.54</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1279 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "493             8.7             0.690         0.31             3.0      0.086   \n",
       "354             6.1             0.210         0.40             1.4      0.066   \n",
       "342            10.9             0.390         0.47             1.8      0.118   \n",
       "834             8.8             0.685         0.26             1.6      0.088   \n",
       "705             8.4             1.035         0.15             6.0      0.073   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1130            9.1             0.600         0.00             1.9      0.058   \n",
       "1294            8.2             0.635         0.10             2.1      0.073   \n",
       "860             7.2             0.620         0.06             2.7      0.077   \n",
       "1459            7.9             0.200         0.35             1.7      0.054   \n",
       "1126            5.8             0.290         0.26             1.7      0.063   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "493                  23.0                  81.0  1.00020  3.48       0.74   \n",
       "354                  40.5                 165.0  0.99120  3.25       0.59   \n",
       "342                   6.0                  14.0  0.99820  3.30       0.75   \n",
       "834                  16.0                  23.0  0.99694  3.32       0.47   \n",
       "705                  11.0                  54.0  0.99900  3.37       0.49   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1130                  5.0                  10.0  0.99770  3.18       0.63   \n",
       "1294                 25.0                  60.0  0.99638  3.29       0.75   \n",
       "860                  15.0                  85.0  0.99746  3.51       0.54   \n",
       "1459                  7.0                  15.0  0.99458  3.32       0.80   \n",
       "1126                  3.0                  11.0  0.99150  3.39       0.54   \n",
       "\n",
       "      alcohol  \n",
       "493      11.6  \n",
       "354      11.9  \n",
       "342       9.8  \n",
       "834       9.4  \n",
       "705       9.9  \n",
       "...       ...  \n",
       "1130     10.4  \n",
       "1294     10.9  \n",
       "860       9.5  \n",
       "1459     11.9  \n",
       "1126     13.5  \n",
       "\n",
       "[1279 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASIC_TEST = 'test.csv'\n",
    "BASIC_TEST_MULTI = 'testmulti.csv'\n",
    "DATA = 'winequality-red.csv'\n",
    "df = pd.read_csv(DATA)\n",
    "X = df.drop(columns='quality')\n",
    "y = df['quality']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 6, 7, 8], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. DECISION TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10341872516716986, 0.5736704082365616)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeRegressor(max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "mse_train = mean_squared_error(y_train, clf.predict(X_train))\n",
    "mse_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "mse_train, mse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.83125)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OVERFITTING TEST\n",
    "clf = MyDecisionTree(max_depth=1000, problem=REGRESSION)\n",
    "clf.fit(X_train, y_train)\n",
    "mse_train = mean_squared_error(y_train, clf.predict(X_train))\n",
    "mse_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "mse_train, mse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6153170022360223, 0.649372938240395)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyDecisionTree(max_depth=20, problem=REGRESSION)\n",
    "clf.fit(X_train, y_train)\n",
    "mse_train = mean_squared_error(y_train, clf.predict(X_train))\n",
    "mse_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "mse_train, mse_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24896996919203196, 0.3639925240600306)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingRegressor(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "mse_train = mean_squared_error(y_train, clf.predict(X_train))\n",
    "mse_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "mse_train, mse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.248969969192032, 0.36250406788524286)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingRegressor(n_estimators=100, lr=0.1, use_sklearn=True)\n",
    "clf.fit(X_train, y_train)\n",
    "mse_train = mean_squared_error(y_train, clf.predict(X_train))\n",
    "mse_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "mse_train, mse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.623452360348013, 0.6649848393001063)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingRegressor(n_estimators=100, lr=0.1, use_sklearn=False)\n",
    "clf.fit(X_train, y_train)\n",
    "mse_train = mean_squared_error(y_train, clf.predict(X_train))\n",
    "mse_val = mean_squared_error(y_val, clf.predict(X_val))\n",
    "mse_train, mse_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9890539483971853, 0.559375)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=15)\n",
    "clf.fit(X_train, y_train)\n",
    "acc_train = accuracy_score(y_train, clf.predict(X_train))\n",
    "acc_val = accuracy_score(y_val, clf.predict(X_val))\n",
    "acc_train, acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9890539483971853, 0.584375)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyDecisionTree(max_depth=15, problem=CLASSIFICATION)\n",
    "clf.fit(X_train, y_train)\n",
    "acc_train = accuracy_score(y_train, clf.predict(X_train))\n",
    "acc_val = accuracy_score(y_val, clf.predict(X_val))\n",
    "acc_train, acc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingMultiClassClassifier(n_estimators=25, max_depth=5, lr=0.1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "acc_train = accuracy_score(y_train, clf.predict(X_train))\n",
    "acc_val = accuracy_score(y_train, clf.predict(X_val))\n",
    "acc_train, acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8749022673964034, 0.6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingMultiClassClassifier(n_estimators=25, max_depth=5, lr=0.1)\n",
    "\n",
    "ytg = np.array(y_train) - 3\n",
    "yvg = np.array(y_val) - 3\n",
    "clf.fit(X_train, ytg)\n",
    "acc_train = accuracy_score(ytg, clf.predict(X_train))\n",
    "acc_val = accuracy_score(yvg, clf.predict(X_val))\n",
    "acc_train, acc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-6\n",
    "\n",
    "class MyGradientBoostingBinaryClassifier:\n",
    "    def __init__(self, n_estimators=10, lr=1e-2, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = []\n",
    "        self.gammas = []\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "        self.threshold = 0.5\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "            y = y.to_numpy()\n",
    "\n",
    "        # STEP 1 - PREDICTOR 0\n",
    "        positives = y.sum()\n",
    "        totals = len(y)\n",
    "        p = positives / totals\n",
    "        self.__first_raw_pred = p\n",
    "        self.__last_raw_preds = np.array([self.__from_pred_to_log_odds(p) for _ in y])\n",
    "\n",
    "        for epoch in range(self.n_estimators):\n",
    "            # STEP 2 - COMPUTE RESIDUALS\n",
    "            probabilities = np.array([self.__from_log_odds_to_pred(log_odds) for log_odds in self.__last_raw_preds])\n",
    "            residuals = y - probabilities\n",
    "\n",
    "            # STEP 3 - CREATE TREE\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residuals)\n",
    "            curr_gammas = self.__compute_gammas(tree, X, y, residuals, probabilities)\n",
    "            self.gammas.append(curr_gammas)\n",
    "            self.estimators.append(tree)\n",
    "\n",
    "            # STEP 4 - UPDATE LAST PREDS\n",
    "            curr_raw_preds = self.__apply_gammas(curr_gammas, tree.apply(X))\n",
    "            self.__last_raw_preds = self.__last_raw_preds + self.lr * curr_raw_preds\n",
    "\n",
    "    def __apply_gammas(self, gammas, leaf_indices):\n",
    "        return np.array([gammas[leaf_idx] for leaf_idx in leaf_indices])\n",
    "\n",
    "    def __compute_gammas(self, tree: DecisionTreeRegressor, X, y, residuals, probabilities):\n",
    "        leafs_indices = tree.apply(X)\n",
    "\n",
    "        sum_residuals_per_leaf = {}\n",
    "        sum_mul_probs_per_leaf = {}\n",
    "        for leaf_idx, sample_idx in zip(leafs_indices, range(len(y))):\n",
    "            sum_residuals_per_leaf[leaf_idx] = sum_residuals_per_leaf.get(leaf_idx, 0) + residuals[sample_idx]\n",
    "            sum_mul_probs_per_leaf[leaf_idx] = sum_mul_probs_per_leaf.get(leaf_idx, 0) + probabilities[sample_idx] * (1 - probabilities[sample_idx])\n",
    "\n",
    "        gammas = {}\n",
    "        unique_leafs_indices = np.unique(leafs_indices)\n",
    "        for leaf_idx in unique_leafs_indices:\n",
    "            gammas[leaf_idx] = sum_residuals_per_leaf[leaf_idx] / sum_mul_probs_per_leaf[leaf_idx]\n",
    "        return gammas\n",
    "\n",
    "    def __from_pred_to_log_odds(self, p):\n",
    "        return np.log((p + EPS) / (1 - p + EPS))\n",
    "    \n",
    "    def __from_log_odds_to_pred(self, logo):\n",
    "        return np.exp(logo) / (1 + np.exp(logo))\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        return np.array([self.__predict_sample(x) for x in X])\n",
    "\n",
    "    def __predict_sample(self, x):\n",
    "        raw_pred = self.__first_raw_pred\n",
    "        for tree, gammas in zip(self.estimators, self.gammas):\n",
    "            raw_pred = raw_pred + self.lr * gammas[tree.apply([x])[0]]\n",
    "        return self.__from_log_odds_to_pred(raw_pred) > self.threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingBinaryClassifier(n_estimators=28, max_depth=5)\n",
    "clf.fit(X_train, y_train)\n",
    "acc_train = accuracy_score(y_train, clf.predict(X_train))\n",
    "acc_val = accuracy_score(y_val, clf.predict(X_val))\n",
    "acc_train, acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-6\n",
    "\n",
    "class MyGradientBoostingMultiClassClassifier:\n",
    "    def __init__(self, n_estimators=10, lr=1e-2, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = []\n",
    "        self.gammas = []\n",
    "        self.lr = lr\n",
    "        self.max_depth = max_depth\n",
    "        self.threshold = 0.5\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "            y = y.to_numpy()\n",
    "\n",
    "        # STEP 0 - convert y to yohe\n",
    "        rows = len(y)\n",
    "        class_count = np.bincount(y)\n",
    "        no_classes = len(class_count)\n",
    "        yohe = self.__to_one_hot_encoded(y, no_classes)\n",
    "\n",
    "        # STEP 1 - PREDICTOR 0\n",
    "        probabilities = class_count / rows\n",
    "        self.__first_raw_pred = [self.__from_pred_to_log_odds(p) for p in probabilities]\n",
    "        self.__last_raw_preds = np.array([self.__first_raw_pred for _ in y])\n",
    "\n",
    "        for epoch in range(self.n_estimators):\n",
    "            # STEP 2 - COMPUTE RESIDUALS\n",
    "            probabilities = np.array([self.__from_log_odds_to_pred_array(log_odds_arr) for log_odds_arr in self.__last_raw_preds])\n",
    "            residuals = yohe - probabilities\n",
    "\n",
    "            # STEP 3 - CREATE TREE\n",
    "            self.gammas.append([])\n",
    "            self.estimators.append([])\n",
    "            for k_class in range(no_classes):\n",
    "                tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "                tree.fit(X, residuals[:, k_class])\n",
    "                curr_gammas = self.__compute_gammas(tree, X, residuals[:, k_class], probabilities[:, k_class])\n",
    "                self.gammas[-1].append(curr_gammas)\n",
    "                self.estimators[-1].append(tree)\n",
    "\n",
    "                # STEP 4 - UPDATE LAST PREDS\n",
    "                curr_raw_preds = self.__apply_gammas(curr_gammas, tree.apply(X))\n",
    "                self.__last_raw_preds[:, k_class] = self.__last_raw_preds[:, k_class] + self.lr * curr_raw_preds\n",
    "\n",
    "    def __to_one_hot_encoded(self, y, no_classes):\n",
    "        # suppose y is an array with classes from 0 to n - 1\n",
    "        rows = len(y)\n",
    "        yohe = np.zeros((rows, no_classes), dtype=int)\n",
    "        yohe[np.arange(rows), y] = 1\n",
    "        return yohe\n",
    "\n",
    "    def __apply_gammas(self, gammas, leaf_indices):\n",
    "        return np.array([gammas[leaf_idx] for leaf_idx in leaf_indices])\n",
    "\n",
    "    def __compute_gammas(self, tree: DecisionTreeRegressor, X, residuals, probabilities):\n",
    "        leafs_indices = tree.apply(X)\n",
    "        no_samples = X.shape[0]\n",
    "\n",
    "        sum_residuals_per_leaf = {}\n",
    "        sum_mul_probs_per_leaf = {}\n",
    "        for leaf_idx, sample_idx in zip(leafs_indices, range(no_samples)):\n",
    "            sum_residuals_per_leaf[leaf_idx] = sum_residuals_per_leaf.get(leaf_idx, 0) + residuals[sample_idx]\n",
    "            sum_mul_probs_per_leaf[leaf_idx] = sum_mul_probs_per_leaf.get(leaf_idx, 0) + probabilities[sample_idx] * (1 - probabilities[sample_idx])\n",
    "\n",
    "        gammas = {}\n",
    "        unique_leafs_indices = np.unique(leafs_indices)\n",
    "        for leaf_idx in unique_leafs_indices:\n",
    "            gammas[leaf_idx] = sum_residuals_per_leaf[leaf_idx] / sum_mul_probs_per_leaf[leaf_idx]\n",
    "        return gammas\n",
    "    \n",
    "    def __from_log_odds_to_pred_array(self, p_array):\n",
    "        return np.array([self.__from_log_odds_to_pred(p) for p in p_array])\n",
    "\n",
    "    # from probability space to raw space\n",
    "    def __from_pred_to_log_odds(self, p):\n",
    "        return np.log((p + EPS) / (1 - p + EPS))\n",
    "    \n",
    "    # from raw space to probability space\n",
    "    def __from_log_odds_to_pred(self, logo):\n",
    "        return np.exp(logo) / (1 + np.exp(logo))\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.to_numpy()\n",
    "        return np.array([self.__predict_sample(x) for x in X])\n",
    "\n",
    "    def __predict_sample(self, x):\n",
    "        raw_pred = np.copy(self.__first_raw_pred)\n",
    "        for trees, gammas in zip(self.estimators, self.gammas):\n",
    "            for class_idx, (tree, gamma) in enumerate(zip(trees, gammas)):\n",
    "                raw_pred[class_idx] = raw_pred[class_idx] + self.lr * gamma[tree.apply([x])[0]]\n",
    "        probabilities = self.__from_log_odds_to_pred_array(raw_pred)\n",
    "        return np.argmax(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8702111024237685, 0.596875)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingMultiClassClassifier(n_estimators=25, max_depth=5, lr=0.1)\n",
    "\n",
    "ytg = np.array(y_train) - 3\n",
    "yvg = np.array(y_val) - 3\n",
    "clf.fit(X_train, ytg)\n",
    "acc_train = accuracy_score(ytg, clf.predict(X_train))\n",
    "acc_val = accuracy_score(yvg, clf.predict(X_val))\n",
    "acc_train, acc_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
